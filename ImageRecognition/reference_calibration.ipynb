{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mediapipe in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (0.10.0)\n",
      "Requirement already satisfied: opencv-python in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: absl-py in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (1.26.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Nicole/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install mediapipe opencv-python\n",
    "\n",
    "# Import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "from threading import Thread\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "\n",
    "# Initialize MediaPipe hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought process behind calibration:\n",
    "\n",
    "\n",
    "Measure distance between users joints, and based on that calculate a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 183\u001b[0m\n\u001b[1;32m    180\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    181\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m--> 183\u001b[0m \u001b[43mprocess_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [40], line 76\u001b[0m, in \u001b[0;36mprocess_webcam\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 0 corresponds to the default webcam\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Display calibration button\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mdisplay_calibration_button\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Display calibration message\u001b[39;00m\n\u001b[1;32m     79\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "Cell \u001b[0;32mIn [40], line 61\u001b[0m, in \u001b[0;36mdisplay_calibration_button\u001b[0;34m(cap)\u001b[0m\n\u001b[1;32m     58\u001b[0m button_image, button_position, button_size \u001b[38;5;241m=\u001b[39m create_calibration_button(frame)  \u001b[38;5;66;03m# Get button position and size\u001b[39;00m\n\u001b[1;32m     60\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHand Tracking\u001b[39m\u001b[38;5;124m'\u001b[39m, button_image)\n\u001b[0;32m---> 61\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to calculate distance between two landmarks\n",
    "def calculate_distance(landmarks, landmark_a, landmark_b):\n",
    "    x_a, y_a = landmarks.landmark[landmark_a].x, landmarks.landmark[landmark_a].y\n",
    "    x_b, y_b = landmarks.landmark[landmark_b].x, landmarks.landmark[landmark_b].y\n",
    "    distance = ((x_b - x_a)**2 + (y_b - y_a)**2)**0.5\n",
    "    return distance\n",
    "\n",
    "# Function to display a message on the screen\n",
    "def display_message(frame, message, duration):\n",
    "    text_size = 1\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    cv2.putText(frame, message, (int(width / 4), int(height / 2)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, text_size, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Hand Tracking', frame)\n",
    "    cv2.waitKey(duration * 1000)\n",
    "\n",
    "button_clicked = False\n",
    "\n",
    "\n",
    "\n",
    "# Function to create and handle the calibration button\n",
    "def create_calibration_button(frame):\n",
    "    button_text = \"Press me to begin calibration process\"\n",
    "    button_size = (650, 100)\n",
    "    button_position = ((frame.shape[1] - button_size[0]) // 2, (frame.shape[0] - button_size[1]) // 2)\n",
    "\n",
    "    # Create a black image with the button text\n",
    "    button_image = frame.copy()\n",
    "    cv2.rectangle(button_image, button_position, (button_position[0] + button_size[0], button_position[1] + button_size[1]), (0, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(button_image, button_text, (button_position[0] + 10, button_position[1] + 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return button_image, button_position, button_size\n",
    "\n",
    "# Mouse event callback function\n",
    "def on_mouse_event(event, x, y, flags, param):\n",
    "    global button_clicked, button_position, button_size\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Check if the click is inside the button's rectangle\n",
    "        button_x, button_y, button_width, button_height = button_position[0], button_position[1], button_size[0], button_size[1]\n",
    "        if button_x < x < button_x + button_width and button_y < y < button_y + button_height:\n",
    "            button_clicked = True\n",
    "\n",
    "# Display calibration button\n",
    "def display_calibration_button(cap):\n",
    "    global button_clicked, button_position, button_size\n",
    "\n",
    "    cv2.namedWindow('Hand Tracking')\n",
    "    cv2.setMouseCallback('Hand Tracking', on_mouse_event)\n",
    "\n",
    "    while not button_clicked:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        button_image, button_position, button_size = create_calibration_button(frame)  # Get button position and size\n",
    "\n",
    "        cv2.imshow('Hand Tracking', button_image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif cv2.getWindowProperty('Hand Tracking', cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Function to process webcam frames\n",
    "def process_webcam():\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)  # 0 corresponds to the default webcam\n",
    "\n",
    "    # Display calibration button\n",
    "    display_calibration_button(cap)\n",
    "    \n",
    "    # Display calibration message\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        display_message(frame, \"Calibration will begin in 5 seconds, please lay your hand flat and do not move\", 5)\n",
    "\n",
    "\n",
    "    # Initialize variables for calibration\n",
    "    calibration_distance = 0\n",
    "    is_calibrating = True\n",
    "    calibration_duration = 3  # seconds\n",
    "\n",
    "    current_distance = 0\n",
    "\n",
    "\n",
    "    # Calibration start time\n",
    "    calibration_start_time = cv2.getTickCount()\n",
    "\n",
    "    # Calibration process\n",
    "    while is_calibrating:\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe hands\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        # If hands are detected, draw landmarks on the frame\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks\n",
    "                mp.solutions.drawing_utils.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Calculate and store the distance during calibration\n",
    "                calibration_distance = calculate_distance(landmarks,\n",
    "                                                            mp_hands.HandLandmark.MIDDLE_FINGER_TIP.value,\n",
    "                                                            mp_hands.HandLandmark.MIDDLE_FINGER_PIP.value)\n",
    "                \n",
    "        # Display calibration message during the 5 seconds\n",
    "        elapsed_time = (cv2.getTickCount() - calibration_start_time) / cv2.getTickFrequency()\n",
    "        if elapsed_time < calibration_duration:\n",
    "            display_message(frame, \"Calibrating...\", 1)\n",
    "\n",
    "        # Calibration complete\n",
    "        else:\n",
    "            is_calibrating = False\n",
    "            display_message(frame, \"Calibration complete. You may now begin playing\", 2)\n",
    "\n",
    "    # Main loop for hand tracking after calibration\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame with MediaPipe hands\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        # If hands are detected, draw landmarks on the frame\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks\n",
    "                mp.solutions.drawing_utils.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)  \n",
    "\n",
    "                # Get landmarks' coordinates\n",
    "                for idx, landmark in enumerate(landmarks.landmark):\n",
    "                    height, width, _ = frame.shape\n",
    "                    cx, cy = int(landmark.x * width), int(landmark.y * height)\n",
    "\n",
    "                    # Draw circles at the tips and proximal phalanges\n",
    "                    if idx in [mp_hands.HandLandmark.MIDDLE_FINGER_TIP.value,\n",
    "                               mp_hands.HandLandmark.MIDDLE_FINGER_PIP.value]:\n",
    "                        cv2.circle(frame, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "\n",
    "                        #calculate current distance\n",
    "                        current_distance = calculate_distance(landmarks,\n",
    "                                                                        mp_hands.HandLandmark.MIDDLE_FINGER_TIP.value,\n",
    "                                                                        mp_hands.HandLandmark.MIDDLE_FINGER_PIP.value)\n",
    "\n",
    "                        if current_distance > 0.9 * calibration_distance:\n",
    "                            # Display a warning if the hand is flat\n",
    "                            warning_text = \"Hand is flat!\"\n",
    "                            text_size = 2  # Increase text size\n",
    "\n",
    "                            # Display text at the top right corner\n",
    "                            cv2.putText(frame, warning_text, (width - 600, 100), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                        text_size, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame with landmarks\n",
    "        cv2.imshow('Hand Tracking', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam capture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "process_webcam()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
